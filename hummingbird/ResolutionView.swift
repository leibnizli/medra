//
//  ResolutionView.swift
//  hummingbird
//
//  ä¿®æ”¹åˆ†è¾¨çŽ‡è§†å›¾
//

import SwiftUI
import PhotosUI
import AVFoundation
import Photos

struct ResolutionView: View {
    @State private var selectedItems: [PhotosPickerItem] = []
    @State private var mediaItems: [MediaItem] = []
    @State private var isProcessing = false
    @State private var targetResolution: ImageResolution = .wallpaperHD
    @State private var customWidth: Int = 1920
    @State private var customHeight: Int = 1080
    
    var body: some View {
        NavigationView {
            VStack(spacing: 0) {
                // é¡¶éƒ¨é€‰æ‹©æŒ‰é’®
                HStack(spacing: 12) {
                    PhotosPicker(selection: $selectedItems, maxSelectionCount: 20, matching: .any(of: [.images, .videos])) {
                        Label("é€‰æ‹©æ–‡ä»¶", systemImage: "photo.on.rectangle.angled")
                            .font(.headline)
                            .frame(maxWidth: .infinity)
                    }
                    .buttonStyle(.borderedProminent)
                    
                    Button(action: startBatchResize) {
                        Label("å¼€å§‹è°ƒæ•´", systemImage: "arrow.up.left.and.arrow.down.right")
                            .font(.headline)
                            .frame(maxWidth: .infinity)
                    }
                    .buttonStyle(.bordered)
                    .disabled(mediaItems.isEmpty || isProcessing)
                }
                .padding()
                
                // åˆ†è¾¨çŽ‡è®¾ç½®
                VStack(spacing: 12) {
                    Picker("ç›®æ ‡åˆ†è¾¨çŽ‡", selection: $targetResolution) {
                        ForEach(ImageResolution.allCases) { resolution in
                            Text(resolution.rawValue).tag(resolution)
                        }
                    }
                    .pickerStyle(.menu)
                    
                    if targetResolution == .custom {
                        HStack(spacing: 12) {
                            HStack {
                                Text("å®½åº¦")
                                TextField("1920", value: $customWidth, format: .number)
                                    .keyboardType(.numberPad)
                                    .textFieldStyle(.roundedBorder)
                                Text("px")
                                    .foregroundStyle(.secondary)
                            }
                            
                            HStack {
                                Text("é«˜åº¦")
                                TextField("1080", value: $customHeight, format: .number)
                                    .keyboardType(.numberPad)
                                    .textFieldStyle(.roundedBorder)
                                Text("px")
                                    .foregroundStyle(.secondary)
                            }
                        }
                    }
                }
                .padding()
                .background(Color(.systemGray6))
                
                Divider()
                
                // æ–‡ä»¶åˆ—è¡¨
                if mediaItems.isEmpty {
                    VStack(spacing: 16) {
                        Image(systemName: "photo.stack")
                            .font(.system(size: 60))
                            .foregroundStyle(.secondary)
                        Text("é€‰æ‹©å›¾ç‰‡æˆ–è§†é¢‘è°ƒæ•´åˆ†è¾¨çŽ‡")
                            .font(.headline)
                            .foregroundStyle(.secondary)
                    }
                    .frame(maxWidth: .infinity, maxHeight: .infinity)
                } else {
                    List {
                        ForEach(mediaItems) { item in
                            ResolutionItemRow(item: item)
                                .listRowInsets(EdgeInsets(top: 6, leading: 16, bottom: 6, trailing: 16))
                                .listRowSeparator(.hidden)
                        }
                        .onDelete { indexSet in
                            withAnimation {
                                mediaItems.remove(atOffsets: indexSet)
                            }
                        }
                    }
                    .listStyle(.plain)
                }
            }
            .navigationTitle("ä¿®æ”¹åˆ†è¾¨çŽ‡")
            .navigationBarTitleDisplayMode(.inline)
        }
        .onChange(of: selectedItems) { _, newItems in
            guard !newItems.isEmpty else { return }
            Task { 
                await loadSelectedItems(newItems)
                await MainActor.run {
                    selectedItems = []
                }
            }
        }
    }
    
    private func loadSelectedItems(_ items: [PhotosPickerItem]) async {
        mediaItems.removeAll()
        
        for item in items {
            let isVideo = item.supportedContentTypes.contains(where: { $0.conforms(to: .movie) || $0.conforms(to: .video) })
            let mediaItem = MediaItem(pickerItem: item, isVideo: isVideo)
            
            if let data = try? await item.loadTransferable(type: Data.self) {
                await MainActor.run {
                    mediaItem.originalData = data
                    mediaItem.originalSize = data.count
                    
                    // æ£€æµ‹åŽŸå§‹å›¾ç‰‡æ ¼å¼ï¼ˆä»Ž PhotosPickerItem çš„ contentType æ£€æµ‹ï¼‰
                    if !isVideo {
                        let isHEIC = item.supportedContentTypes.contains { contentType in
                            contentType.identifier == "public.heic" || 
                            contentType.identifier == "public.heif" ||
                            contentType.conforms(to: .heic) ||
                            contentType.conforms(to: .heif)
                        }
                        mediaItem.originalImageFormat = isHEIC ? .heic : .jpeg
                        print("ðŸ“‹ [åˆ†è¾¨çŽ‡-æ ¼å¼æ£€æµ‹] PhotosPickerItem æ ¼å¼: \(isHEIC ? "HEIC" : "JPEG")")
                    }
                    
                    if isVideo {
                        let tempURL = URL(fileURLWithPath: NSTemporaryDirectory())
                            .appendingPathComponent("source_\(mediaItem.id.uuidString)")
                            .appendingPathExtension("mov")
                        try? data.write(to: tempURL)
                        mediaItem.sourceVideoURL = tempURL
                        
                        let asset = AVURLAsset(url: tempURL)
                        if let videoTrack = asset.tracks(withMediaType: .video).first {
                            let size = videoTrack.naturalSize
                            let transform = videoTrack.preferredTransform
                            let isPortrait = abs(transform.b) == 1.0 || abs(transform.c) == 1.0
                            mediaItem.originalResolution = isPortrait ? CGSize(width: size.height, height: size.width) : size
                        }
                        
                        generateVideoThumbnail(for: mediaItem, url: tempURL)
                    } else {
                        if let image = UIImage(data: data) {
                            mediaItem.thumbnailImage = generateThumbnail(from: image)
                            mediaItem.originalResolution = image.size
                        }
                    }
                }
            }
            
            await MainActor.run {
                mediaItems.append(mediaItem)
            }
        }
    }
    
    private func generateThumbnail(from image: UIImage, size: CGSize = CGSize(width: 80, height: 80)) -> UIImage? {
        let aspectRatio = image.size.width / image.size.height
        let targetAspectRatio = size.width / size.height
        
        var targetSize = size
        if aspectRatio > targetAspectRatio {
            targetSize.height = size.width / aspectRatio
        } else {
            targetSize.width = size.height * aspectRatio
        }
        
        let renderer = UIGraphicsImageRenderer(size: targetSize)
        return renderer.image { _ in
            image.draw(in: CGRect(origin: .zero, size: targetSize))
        }
    }
    
    private func generateVideoThumbnail(for item: MediaItem, url: URL) {
        let asset = AVURLAsset(url: url)
        let generator = AVAssetImageGenerator(asset: asset)
        generator.appliesPreferredTrackTransform = true
        generator.maximumSize = CGSize(width: 160, height: 160)
        
        Task {
            do {
                let cgImage = try await generator.image(at: .zero).image
                let thumbnail = UIImage(cgImage: cgImage)
                await MainActor.run {
                    item.thumbnailImage = thumbnail
                }
            } catch {
                print("ç”Ÿæˆè§†é¢‘ç¼©ç•¥å›¾å¤±è´¥: \(error)")
            }
        }
    }
    
    private func startBatchResize() {
        isProcessing = true
        
        Task {
            // é‡ç½®æ‰€æœ‰é¡¹ç›®çŠ¶æ€ï¼Œä»¥ä¾¿é‡æ–°å¤„ç†
            await MainActor.run {
                for item in mediaItems {
                    item.status = .pending
                    item.progress = 0
                    item.compressedData = nil
                    item.compressedSize = 0
                    item.compressedResolution = nil
                    item.compressedVideoURL = nil
                    item.usedBitrate = nil
                    item.errorMessage = nil
                }
            }
            
            for item in mediaItems {
                await resizeItem(item)
            }
            await MainActor.run {
                isProcessing = false
            }
        }
    }
    
    private func resizeItem(_ item: MediaItem) async {
        await MainActor.run {
            item.status = .processing
            item.progress = 0
        }
        
        if item.isVideo {
            await resizeVideo(item)
        } else {
            await resizeImage(item)
        }
    }
    
    private func resizeImage(_ item: MediaItem) async {
        guard let originalData = item.originalData else {
            await MainActor.run {
                item.status = .failed
                item.errorMessage = "æ— æ³•åŠ è½½åŽŸå§‹å›¾ç‰‡"
            }
            return
        }
        
        guard var image = UIImage(data: originalData) else {
            await MainActor.run {
                item.status = .failed
                item.errorMessage = "æ— æ³•è§£ç å›¾ç‰‡"
            }
            return
        }
        
        // ä½¿ç”¨åŽŸå§‹æ ¼å¼ï¼ˆä»Ž item ä¸­èŽ·å–ï¼‰
        let originalFormat = item.originalImageFormat ?? .jpeg
        
        // ä¿®æ­£æ–¹å‘
        image = image.fixOrientation()
        
        // èŽ·å–ç›®æ ‡å°ºå¯¸å¹¶è¿›è¡Œæ™ºèƒ½è£å‰ªå’Œç¼©æ”¾
        if let (width, height) = getTargetSize() {
            image = resizeAndCropImage(image, targetWidth: width, targetHeight: height)
        }
        
        // ä½¿ç”¨ç³»ç»ŸåŽŸç”Ÿç¼–ç ï¼ˆä¸è°ƒç”¨åŽ‹ç¼©ï¼‰ï¼Œä¿æŒé«˜è´¨é‡
        let resizedData: Data
        if originalFormat == .heic {
            // HEIC æ ¼å¼
            if #available(iOS 11.0, *) {
                let mutableData = NSMutableData()
                if let cgImage = image.cgImage,
                   let destination = CGImageDestinationCreateWithData(mutableData, AVFileType.heic as CFString, 1, nil) {
                    let options: [CFString: Any] = [kCGImageDestinationLossyCompressionQuality: 0.9]
                    CGImageDestinationAddImage(destination, cgImage, options as CFDictionary)
                    if CGImageDestinationFinalize(destination) {
                        resizedData = mutableData as Data
                        print("âœ… [åˆ†è¾¨çŽ‡è°ƒæ•´] HEIC ç¼–ç æˆåŠŸ - å¤§å°: \(resizedData.count) bytes")
                    } else {
                        await MainActor.run {
                            item.status = .failed
                            item.errorMessage = "HEIC ç¼–ç å¤±è´¥"
                        }
                        return
                    }
                } else {
                    await MainActor.run {
                        item.status = .failed
                        item.errorMessage = "æ— æ³•åˆ›å»º HEIC ç¼–ç å™¨"
                    }
                    return
                }
            } else {
                // iOS 11 ä»¥ä¸‹ä¸æ”¯æŒ HEICï¼Œå›žé€€åˆ° JPEG
                guard let jpegData = image.jpegData(compressionQuality: 0.9) else {
                    await MainActor.run {
                        item.status = .failed
                        item.errorMessage = "æ— æ³•ç¼–ç å›¾ç‰‡"
                    }
                    return
                }
                resizedData = jpegData
                print("âœ… [åˆ†è¾¨çŽ‡è°ƒæ•´] JPEG ç¼–ç æˆåŠŸï¼ˆHEIC ä¸æ”¯æŒï¼‰ - å¤§å°: \(resizedData.count) bytes")
            }
        } else {
            // JPEG æ ¼å¼ - ä½¿ç”¨ç³»ç»ŸåŽŸç”Ÿç¼–ç 
            guard let jpegData = image.jpegData(compressionQuality: 0.9) else {
                await MainActor.run {
                    item.status = .failed
                    item.errorMessage = "æ— æ³•ç¼–ç å›¾ç‰‡"
                }
                return
            }
            resizedData = jpegData
            print("âœ… [åˆ†è¾¨çŽ‡è°ƒæ•´] JPEG ç¼–ç æˆåŠŸ - å¤§å°: \(resizedData.count) bytes")
        }
        
        await MainActor.run {
            item.compressedData = resizedData
            item.compressedSize = resizedData.count
            item.compressedResolution = image.size
            item.outputImageFormat = originalFormat  // è®°å½•è¾“å‡ºæ ¼å¼
            item.status = .completed
            item.progress = 1.0
        }
    }
    
    // æ™ºèƒ½ç¼©æ”¾å’Œè£å‰ªå›¾ç‰‡åˆ°ç›®æ ‡å°ºå¯¸
    private func resizeAndCropImage(_ image: UIImage, targetWidth: Int, targetHeight: Int) -> UIImage {
        let originalSize = image.size
        let targetSize = CGSize(width: targetWidth, height: targetHeight)
        
        // è®¡ç®—ç›®æ ‡å®½é«˜æ¯”å’ŒåŽŸå§‹å®½é«˜æ¯”
        let targetAspectRatio = CGFloat(targetWidth) / CGFloat(targetHeight)
        let originalAspectRatio = originalSize.width / originalSize.height
        
        // è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼Œä½¿ç”¨è¾ƒå¤§çš„æ¯”ä¾‹ä»¥ç¡®ä¿å¡«æ»¡ç›®æ ‡å°ºå¯¸
        let scale: CGFloat
        if originalAspectRatio > targetAspectRatio {
            // åŽŸå›¾æ›´å®½ï¼Œä»¥é«˜åº¦ä¸ºå‡†ç¼©æ”¾
            scale = targetSize.height / originalSize.height
        } else {
            // åŽŸå›¾æ›´é«˜æˆ–ç›¸åŒï¼Œä»¥å®½åº¦ä¸ºå‡†ç¼©æ”¾
            scale = targetSize.width / originalSize.width
        }
        
        // ç¼©æ”¾åŽçš„å°ºå¯¸
        let scaledSize = CGSize(
            width: originalSize.width * scale,
            height: originalSize.height * scale
        )
        
        // è®¡ç®—è£å‰ªåŒºåŸŸï¼ˆå±…ä¸­è£å‰ªï¼‰
        let cropRect = CGRect(
            x: (scaledSize.width - targetSize.width) / 2,
            y: (scaledSize.height - targetSize.height) / 2,
            width: targetSize.width,
            height: targetSize.height
        )
        
        // åˆ›å»ºæ¸²æŸ“å™¨
        let format = UIGraphicsImageRendererFormat()
        format.scale = 1.0
        format.opaque = false
        
        // å…ˆç¼©æ”¾åˆ°åˆé€‚å¤§å°
        let scaledRenderer = UIGraphicsImageRenderer(size: scaledSize, format: format)
        let scaledImage = scaledRenderer.image { _ in
            image.draw(in: CGRect(origin: .zero, size: scaledSize))
        }
        
        // ç„¶åŽè£å‰ªåˆ°ç›®æ ‡å°ºå¯¸
        let cropRenderer = UIGraphicsImageRenderer(size: targetSize, format: format)
        return cropRenderer.image { _ in
            scaledImage.draw(at: CGPoint(x: -cropRect.origin.x, y: -cropRect.origin.y))
        }
    }
    
    private func resizeVideo(_ item: MediaItem) async {
        guard let sourceURL = item.sourceVideoURL else {
            await MainActor.run {
                item.status = .failed
                item.errorMessage = "æ— æ³•åŠ è½½åŽŸå§‹è§†é¢‘"
            }
            return
        }
        
        let asset = AVURLAsset(url: sourceURL)
        guard let exportSession = AVAssetExportSession(asset: asset, presetName: AVAssetExportPresetHighestQuality) else {
            await MainActor.run {
                item.status = .failed
                item.errorMessage = "æ— æ³•åˆ›å»ºå¯¼å‡ºä¼šè¯"
            }
            return
        }
        
        let outputURL = URL(fileURLWithPath: NSTemporaryDirectory())
            .appendingPathComponent("resized_\(UUID().uuidString)")
            .appendingPathExtension("mp4")
        
        exportSession.outputURL = outputURL
        exportSession.outputFileType = .mp4
        exportSession.shouldOptimizeForNetworkUse = true
        
        // è®¾ç½®è§†é¢‘åˆ†è¾¨çŽ‡
        if let (width, height) = getTargetSize() {
            let size = CGSize(width: width, height: height)
            exportSession.videoComposition = createVideoComposition(asset: asset, targetSize: size)
        }
        
        let timer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { t in
            Task { @MainActor in
                item.progress = exportSession.progress
            }
            if exportSession.status != .exporting { t.invalidate() }
        }
        RunLoop.main.add(timer, forMode: .common)
        
        await exportSession.export()
        
        await MainActor.run {
            switch exportSession.status {
            case .completed:
                item.compressedVideoURL = outputURL
                if let data = try? Data(contentsOf: outputURL) {
                    item.compressedSize = data.count
                }
                
                let resultAsset = AVURLAsset(url: outputURL)
                if let videoTrack = resultAsset.tracks(withMediaType: .video).first {
                    let size = videoTrack.naturalSize
                    let transform = videoTrack.preferredTransform
                    let isPortrait = abs(transform.b) == 1.0 || abs(transform.c) == 1.0
                    item.compressedResolution = isPortrait ? CGSize(width: size.height, height: size.width) : size
                }
                
                item.status = .completed
                item.progress = 1.0
            default:
                item.status = .failed
                item.errorMessage = exportSession.error?.localizedDescription ?? "å¯¼å‡ºå¤±è´¥"
            }
        }
    }
    
    // åˆ›å»ºè§†é¢‘åˆæˆï¼Œå®žçŽ°æ™ºèƒ½ç¼©æ”¾å’Œè£å‰ª
    private func createVideoComposition(asset: AVAsset, targetSize: CGSize) -> AVMutableVideoComposition {
        guard let videoTrack = asset.tracks(withMediaType: .video).first else {
            return AVMutableVideoComposition()
        }
        
        let composition = AVMutableVideoComposition()
        composition.renderSize = targetSize
        composition.frameDuration = CMTime(value: 1, timescale: 30)
        
        let instruction = AVMutableVideoCompositionInstruction()
        instruction.timeRange = CMTimeRange(start: .zero, duration: asset.duration)
        
        let transformer = AVMutableVideoCompositionLayerInstruction(assetTrack: videoTrack)
        
        // èŽ·å–è§†é¢‘åŽŸå§‹å°ºå¯¸å’Œæ–¹å‘
        let videoSize = videoTrack.naturalSize
        let transform = videoTrack.preferredTransform
        let isPortrait = abs(transform.b) == 1.0 || abs(transform.c) == 1.0
        let actualSize = isPortrait ? CGSize(width: videoSize.height, height: videoSize.width) : videoSize
        
        // è®¡ç®—å®½é«˜æ¯”
        let targetAspectRatio = targetSize.width / targetSize.height
        let videoAspectRatio = actualSize.width / actualSize.height
        
        // ä½¿ç”¨è¾ƒå¤§çš„ç¼©æ”¾æ¯”ä¾‹ä»¥å¡«æ»¡ç›®æ ‡å°ºå¯¸ï¼ˆä¼šè£å‰ªè¶…å‡ºéƒ¨åˆ†ï¼‰
        let scale: CGFloat
        if videoAspectRatio > targetAspectRatio {
            // è§†é¢‘æ›´å®½ï¼Œä»¥é«˜åº¦ä¸ºå‡†
            scale = targetSize.height / actualSize.height
        } else {
            // è§†é¢‘æ›´é«˜ï¼Œä»¥å®½åº¦ä¸ºå‡†
            scale = targetSize.width / actualSize.width
        }
        
        // è®¡ç®—ç¼©æ”¾åŽçš„å°ºå¯¸
        let scaledSize = CGSize(width: actualSize.width * scale, height: actualSize.height * scale)
        
        // è®¡ç®—å±…ä¸­åç§»
        let tx = (targetSize.width - scaledSize.width) / 2
        let ty = (targetSize.height - scaledSize.height) / 2
        
        // æž„å»ºå˜æ¢çŸ©é˜µ
        var finalTransform = CGAffineTransform.identity
        
        // å…ˆåº”ç”¨åŽŸå§‹çš„æ—‹è½¬/ç¿»è½¬å˜æ¢
        finalTransform = finalTransform.concatenating(transform)
        
        // ç„¶åŽç¼©æ”¾
        finalTransform = finalTransform.scaledBy(x: scale, y: scale)
        
        // æœ€åŽå¹³ç§»åˆ°å±…ä¸­ä½ç½®
        if isPortrait {
            // ç«–å±è§†é¢‘éœ€è¦ç‰¹æ®Šå¤„ç†åç§»
            finalTransform = finalTransform.translatedBy(x: ty, y: tx)
        } else {
            finalTransform = finalTransform.translatedBy(x: tx, y: ty)
        }
        
        transformer.setTransform(finalTransform, at: .zero)
        instruction.layerInstructions = [transformer]
        composition.instructions = [instruction]
        
        return composition
    }
    
    private func getTargetSize() -> (Int, Int)? {
        if targetResolution == .custom {
            return (customWidth, customHeight)
        } else if let size = targetResolution.size {
            return (size.width, size.height)
        }
        return nil
    }
}

#Preview {
    ResolutionView()
}
